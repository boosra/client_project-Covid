{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gensim\n",
    "import re\n",
    "import cudl\n",
    "\n",
    "from numba import jit, cuda\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from cuml import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_remover(df):\n",
    "    df['text'] = df['text'].astype(str).str.lower()\n",
    "    df['token_text'] = df['text'].str.replace('([^ a-zA-Z0-9])', '').str.replace('http\\S+|www.\\S+', '', case=False).replace('coronavirus', \n",
    "                                                                                                                            'covid19')\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    df['stop_text'] = df['token_text'].apply(lambda x: [item for item in str(x).split() \n",
    "                                                    if item not in stop])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../adam/datasets/scrape_5.12.csv')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121482, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114044, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop_duplicates(inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = stop_word_remover(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('../adam/datasets/test_5.14.csv')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221214, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201794, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.drop_duplicates(inplace=True)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = stop_word_remover(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315838, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2], ignore_index = True, verify_integrity = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.\n",
       "1    looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                    \n",
       "2    humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                            \n",
       "3    had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                    \n",
       "4    #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                       \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]\n",
       "1    [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                  \n",
       "2    [humoursnlon, covid, coronavirususa]                                                                                                                                                \n",
       "3    [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]              \n",
       "4    [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                         \n",
       "Name: stop_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough\n",
       "1    looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                    \n",
       "2    humoursnlon covid coronavirususa                                                                                                                                                                                                     \n",
       "3    had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan               \n",
       "4    covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                 \n",
       "Name: token_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row for row in df1['stop_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v = Word2Vec(size=dims, min_count=500, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v.build_vocab(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('america', 0.1774219572544098),\n",
       " ('trumps', 0.15831056237220764),\n",
       " ('going', 0.1576019823551178),\n",
       " ('treatment', 0.1463635116815567),\n",
       " ('today', 0.13153408467769623),\n",
       " ('found', 0.12964557111263275),\n",
       " ('become', 0.12547096610069275),\n",
       " ('socialdistancing', 0.12408412247896194),\n",
       " ('already', 0.12144090980291367),\n",
       " ('says', 0.11682413518428802)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions found in this cell were created by instructor Noah Christiansen\n",
    "# He is great\n",
    "# Define vectorization function\n",
    "#word2vecmodel = tweet_w2v\n",
    "def vectorize_corpus(keyword_list):    \n",
    "    # Instantiate counter for number of words in keyword_list that exists\n",
    "    n_words = 0\n",
    "    # Create template for cumulative corpus vector sum\n",
    "    corpus_vec_sum = np.zeros((1,dims))                 \n",
    "    # Scan through each word in list\n",
    "    for word in keyword_list:\n",
    "        if word in tweet_w2v.wv.vocab:                    \n",
    "            word_vec = tweet_w2v.wv.word_vec(word)\n",
    "            #print(word_vec)\n",
    "            n_words +=1                                \n",
    "            corpus_vec_sum = corpus_vec_sum + word_vec \n",
    "    # Compute average vector by taking cumulative vector sum and dividing it by number of words traced\n",
    "    corpus_avg_vec = corpus_vec_sum/n_words\n",
    "    # Squeeze this N-dimensional nested array object into a 1-D array to streamline future processing\n",
    "    corpus_avg_vec = np.squeeze(corpus_avg_vec)\n",
    "    return(corpus_avg_vec)\n",
    "\n",
    "#defining cosine similarity function\n",
    "def cos_sim(vector_1, vector_2):\n",
    "    dp = np.dot(vector_1, vector_2)\n",
    "    magnitude_v1 = np.sqrt(np.dot(vector_1,vector_1))\n",
    "    magnitude_v2 = np.sqrt(np.dot(vector_2,vector_2))\n",
    "    return(dp/(magnitude_v1*magnitude_v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "vect_tweets = [vectorize_corpus(tweet) for tweet in df['stop_text']]\n",
    "vect_df = pd.DataFrame(vect_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315838, 12)\n",
      "(315838, 300)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(vect_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293497, 312)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df = df.join(vect_df)\n",
    "join_df.dropna(inplace = True)\n",
    "join_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.001556</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000576</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000358</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.000036 -0.000318 -0.000159 -0.000425  0.000237  0.000169 -0.000201   \n",
       "1  0.000184 -0.000228  0.000042 -0.000009  0.000122 -0.000426 -0.000161   \n",
       "2  0.000271 -0.000080 -0.001618  0.000013 -0.000597 -0.000060 -0.000231   \n",
       "3  0.000576 -0.000205 -0.000070 -0.000082 -0.000107  0.000277  0.000405   \n",
       "4  0.000431 -0.000456 -0.001382  0.000116 -0.000748 -0.000358 -0.000909   \n",
       "\n",
       "          8         9        10  ...       290       291       292       293  \\\n",
       "0 -0.000051 -0.000067  0.000510  ... -0.000107  0.000111  0.000009 -0.000047   \n",
       "1 -0.000141  0.000470 -0.000351  ...  0.000646  0.000715 -0.000258 -0.000621   \n",
       "2 -0.001556 -0.000579 -0.000073  ...  0.000895  0.001244  0.000246  0.000535   \n",
       "3 -0.000229  0.000167 -0.000346  ...  0.000017  0.000487  0.000124  0.000656   \n",
       "4  0.000350  0.000042  0.000065  ...  0.000661  0.000008 -0.000140 -0.000209   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.000154 -0.000091 -0.000100  0.000008  0.000212  0.000752  \n",
       "1 -0.000584 -0.000349 -0.000400  0.000185  0.000665  0.000882  \n",
       "2 -0.001173 -0.001518 -0.000017 -0.000595  0.001266  0.000610  \n",
       "3 -0.000577 -0.000370  0.000295 -0.000323 -0.000345 -0.000208  \n",
       "4 -0.000455  0.000587  0.000043  0.000705  0.000736  0.000214  \n",
       "\n",
       "[5 rows x 299 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vec_df= join_df.iloc[:, [i for i in range(13,(dims+12))]]\n",
    "clean_og_df = join_df.iloc[:, [i for i in range(0,12)]]\n",
    "clean_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough</td>\n",
       "      <td>[first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>looks like adios muchachos for the us covid covid19us coronavirus</td>\n",
       "      <td>[looks, like, adios, muchachos, us, covid, covid19us, coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>humoursnlon covid coronavirususa</td>\n",
       "      <td>[humoursnlon, covid, coronavirususa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>¬∞ ¬∞ ¬∞</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan</td>\n",
       "      <td>[go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>#covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120</td>\n",
       "      <td>[covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "3  1234238588474331136  ¬∞ ¬∞ ¬∞                        \n",
       "4  1234238537068883968  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.   \n",
       "1  looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                       \n",
       "2  humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \\\n",
       "0  2020-02-01   \n",
       "1  2020-02-01   \n",
       "2  2020-02-01   \n",
       "3  2020-02-01   \n",
       "4  2020-02-01   \n",
       "\n",
       "                                                                                                                                                                                                                              token_text  \\\n",
       "0  did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough   \n",
       "1  looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                       \n",
       "2  humoursnlon covid coronavirususa                                                                                                                                                                                                        \n",
       "3  had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan                  \n",
       "4  covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                              stop_text  \n",
       "0  [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]  \n",
       "1  [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                    \n",
       "2  [humoursnlon, covid, coronavirususa]                                                                                                                                                  \n",
       "3  [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]                \n",
       "4  [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                           "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(metric='cosine', eps=0.1, min_samples=25, n_jobs = -1) # you can change these parameters, given just for example \n",
    "cluster_labels = dbscan.fit_predict(clean_vec_df) # where X - is your matrix, where each row corresponds to one document (line) from the docs, you need to cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamr\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "clean_og_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     156234\n",
       "-1     136365\n",
       " 18    144   \n",
       " 9     84    \n",
       " 2     83    \n",
       " 19    49    \n",
       " 17    42    \n",
       " 8     39    \n",
       " 13    35    \n",
       " 22    34    \n",
       " 14    34    \n",
       " 16    32    \n",
       " 3     30    \n",
       " 12    30    \n",
       " 21    28    \n",
       " 7     27    \n",
       " 1     27    \n",
       " 5     26    \n",
       " 10    25    \n",
       " 6     25    \n",
       " 4     25    \n",
       " 15    25    \n",
       " 20    25    \n",
       " 11    25    \n",
       " 23    4     \n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough</td>\n",
       "      <td>[first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>looks like adios muchachos for the us covid covid19us coronavirus</td>\n",
       "      <td>[looks, like, adios, muchachos, us, covid, covid19us, coronavirus]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>humoursnlon covid coronavirususa</td>\n",
       "      <td>[humoursnlon, covid, coronavirususa]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>¬∞ ¬∞ ¬∞</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan</td>\n",
       "      <td>[go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>#covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120</td>\n",
       "      <td>[covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "3  1234238588474331136  ¬∞ ¬∞ ¬∞                        \n",
       "4  1234238537068883968  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.   \n",
       "1  looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                       \n",
       "2  humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \\\n",
       "0  2020-02-01   \n",
       "1  2020-02-01   \n",
       "2  2020-02-01   \n",
       "3  2020-02-01   \n",
       "4  2020-02-01   \n",
       "\n",
       "                                                                                                                                                                                                                              token_text  \\\n",
       "0  did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough   \n",
       "1  looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                       \n",
       "2  humoursnlon covid coronavirususa                                                                                                                                                                                                        \n",
       "3  had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan                  \n",
       "4  covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                              stop_text  \\\n",
       "0  [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]   \n",
       "1  [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                     \n",
       "2  [humoursnlon, covid, coronavirususa]                                                                                                                                                   \n",
       "3  [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]                 \n",
       "4  [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                            \n",
       "\n",
       "   cluster  \n",
       "0 -1        \n",
       "1  0        \n",
       "2  0        \n",
       "3 -1        \n",
       "4 -1        "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other        15253\n",
       "test         10975\n",
       "medical      8835 \n",
       "student      7180 \n",
       "#COVID-19    6794 \n",
       "#covid19     6738 \n",
       "hot          4343 \n",
       "round        4169 \n",
       "table        3433 \n",
       "sale         2918 \n",
       "Name: search_term, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = clean_og_df['cluster'] == -1\n",
    "clean_og_df[mask]['search_term'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_og_df.to_csv(r'./datasets/full_dataset.csv', compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
