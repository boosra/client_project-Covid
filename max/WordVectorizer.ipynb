{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gensim\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../adam/datasets/scrape_5.12.csv')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>Did the first of several shopping runs, though I ended up walking out of CVS without buying anything. If the rate of people coughing at me is any indication, we’ll all have Covid-19 by Thursday. \\n\\nCover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>Looks like adios muchachos for the US #COVID #COVID19US #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>Humour..snl...on #COVID #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>° ° °</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>#COVID #Coronovirius in nursing home setting , #Kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "3  1234238588474331136  ° ° °                        \n",
       "4  1234238537068883968  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  Did the first of several shopping runs, though I ended up walking out of CVS without buying anything. If the rate of people coughing at me is any indication, we’ll all have Covid-19 by Thursday. \\n\\nCover your fucking mouths when you cough.   \n",
       "1  Looks like adios muchachos for the US #COVID #COVID19US #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …                                                                                                                       \n",
       "2  Humour..snl...on #COVID #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #COVID #Coronovirius in nursing home setting , #Kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \n",
       "0  2020-02-01  \n",
       "1  2020-02-01  \n",
       "2  2020-02-01  \n",
       "3  2020-02-01  \n",
       "4  2020-02-01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114044, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str).str.lower()\n",
    "df['token_text'] = df['text'].str.replace('([^ a-zA-Z0-9])', '').str.replace('http\\S+|www.\\S+', '', case=False).replace('coronavirus', 'covid19')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['stop_text'] = df['token_text'].apply(lambda x: [item for item in str(x).split() \n",
    "                                                    if item not in stop])\n",
    "\n",
    "\n",
    "\n",
    "#df['split_text'] = df['token_text'].astype(str).str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we’ll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.\n",
       "1    looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …                                                                                                                    \n",
       "2    humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …                                                                                                                            \n",
       "3    had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                    \n",
       "4    #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …                                       \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]\n",
       "1    [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                  \n",
       "2    [humoursnlon, covid, coronavirususa]                                                                                                                                                \n",
       "3    [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]              \n",
       "4    [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                         \n",
       "Name: stop_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough\n",
       "1    looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                    \n",
       "2    humoursnlon covid coronavirususa                                                                                                                                                                                                     \n",
       "3    had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan               \n",
       "4    covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                 \n",
       "Name: token_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row for row in df['stop_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v = Word2Vec(size=dims, min_count=500, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v.build_vocab(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-61-2b571b920e4a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-2b571b920e4a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -W ignore foo.py\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dying', 0.15527953207492828),\n",
       " ('families', 0.13991212844848633),\n",
       " ('virus', 0.13581764698028564),\n",
       " ('word', 0.1346871256828308),\n",
       " ('cuomo', 0.12684494256973267),\n",
       " ('covid19', 0.12572665512561798),\n",
       " ('coronavirus', 0.12061143666505814),\n",
       " ('wait', 0.11820172518491745),\n",
       " ('hit', 0.11507762223482132),\n",
       " ('hospital', 0.11272245645523071)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions found in this cell were created by instructor Noah Christiansen\n",
    "# He is great\n",
    "# Define vectorization function\n",
    "#word2vecmodel = tweet_w2v\n",
    "def vectorize_corpus(keyword_list):    \n",
    "    # Instantiate counter for number of words in keyword_list that exists\n",
    "    n_words = 0\n",
    "    # Create template for cumulative corpus vector sum\n",
    "    corpus_vec_sum = np.zeros((1,dims))                 \n",
    "    # Scan through each word in list\n",
    "    for word in keyword_list:\n",
    "        if word in tweet_w2v.wv.vocab:                    \n",
    "            word_vec = tweet_w2v.wv.word_vec(word)\n",
    "            #print(word_vec)\n",
    "            n_words +=1                                \n",
    "            corpus_vec_sum = corpus_vec_sum + word_vec \n",
    "    # Compute average vector by taking cumulative vector sum and dividing it by number of words traced\n",
    "    corpus_avg_vec = corpus_vec_sum/n_words\n",
    "    # Squeeze this N-dimensional nested array object into a 1-D array to streamline future processing\n",
    "    corpus_avg_vec = np.squeeze(corpus_avg_vec)\n",
    "    return(corpus_avg_vec)\n",
    "\n",
    "#defining cosine similarity function\n",
    "def cos_sim(vector_1, vector_2):\n",
    "    dp = np.dot(vector_1, vector_2)\n",
    "    magnitude_v1 = np.sqrt(np.dot(vector_1,vector_1))\n",
    "    magnitude_v2 = np.sqrt(np.dot(vector_2,vector_2))\n",
    "    return(dp/(magnitude_v1*magnitude_v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "vect_tweets = [vectorize_corpus(tweet) for tweet in df['stop_text']]\n",
    "vect_df = pd.DataFrame(vect_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = df.join(vect_df)\n",
    "join_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.000756</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001397</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>-0.001638</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000279</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>-0.000366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0 -0.000024 -0.000150 -0.000048  0.000085  0.000195 -0.000267  0.000478   \n",
       "1  0.000107  0.000460  0.000255 -0.000756  0.000804  0.000376 -0.000670   \n",
       "2 -0.001397  0.001080  0.000031 -0.000252  0.001550  0.000673  0.000113   \n",
       "3  0.000057  0.000103  0.000413  0.000836  0.000500  0.000244 -0.000459   \n",
       "4 -0.000279  0.000350 -0.000442  0.000284  0.000056  0.000294 -0.000305   \n",
       "\n",
       "          8         9        10  ...       290       291       292       293  \\\n",
       "0  0.000076 -0.000223  0.000285  ... -0.000186  0.000150  0.000214 -0.000255   \n",
       "1 -0.000481 -0.000033 -0.000403  ...  0.000555 -0.000191 -0.000426  0.001006   \n",
       "2 -0.000339  0.000781 -0.001182  ...  0.001232  0.000826 -0.001434  0.000438   \n",
       "3  0.000508 -0.000049 -0.000581  ...  0.000004  0.000183  0.000134  0.000156   \n",
       "4 -0.000387 -0.000098 -0.000539  ...  0.000244 -0.000481 -0.000491  0.000645   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.000589 -0.000761 -0.000461  0.000140  0.000590  0.000113  \n",
       "1  0.000882 -0.000068 -0.000572 -0.000056  0.000261 -0.000285  \n",
       "2  0.000435  0.000739 -0.001638  0.000827  0.000510 -0.001221  \n",
       "3 -0.000331  0.000582 -0.000457  0.000280  0.000314  0.000228  \n",
       "4 -0.000263 -0.000085 -0.000663  0.000585  0.000237 -0.000366  \n",
       "\n",
       "[5 rows x 299 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vec_df= join_df.iloc[:, [i for i in range(13,dims+12)]]\n",
    "clean_og_df = join_df.iloc[:, [i for i in range(0,12)]]\n",
    "clean_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we’ll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough</td>\n",
       "      <td>[first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>looks like adios muchachos for the us covid covid19us coronavirus</td>\n",
       "      <td>[looks, like, adios, muchachos, us, covid, covid19us, coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>humoursnlon covid coronavirususa</td>\n",
       "      <td>[humoursnlon, covid, coronavirususa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>° ° °</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan</td>\n",
       "      <td>[go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>#covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120</td>\n",
       "      <td>[covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "3  1234238588474331136  ° ° °                        \n",
       "4  1234238537068883968  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we’ll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.   \n",
       "1  looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …                                                                                                                       \n",
       "2  humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \\\n",
       "0  2020-02-01   \n",
       "1  2020-02-01   \n",
       "2  2020-02-01   \n",
       "3  2020-02-01   \n",
       "4  2020-02-01   \n",
       "\n",
       "                                                                                                                                                                                                                              token_text  \\\n",
       "0  did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough   \n",
       "1  looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                       \n",
       "2  humoursnlon covid coronavirususa                                                                                                                                                                                                        \n",
       "3  had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan                  \n",
       "4  covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                              stop_text  \n",
       "0  [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]  \n",
       "1  [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                    \n",
       "2  [humoursnlon, covid, coronavirususa]                                                                                                                                                  \n",
       "3  [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]                \n",
       "4  [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                           "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(metric='cosine', eps=0.4, min_samples=30, n_jobs = -1) # you can change these parameters, given just for example \n",
    "cluster_labels = dbscan.fit_predict(clean_vec_df) # where X - is your matrix, where each row corresponds to one document (line) from the docs, you need to cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "clean_og_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    76084\n",
       "-1    31196\n",
       " 2    80   \n",
       " 1    39   \n",
       " 3    33   \n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>looks like adios muchachos for the us covid covid19us coronavirus</td>\n",
       "      <td>[looks, like, adios, muchachos, us, covid, covid19us, coronavirus]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>humoursnlon covid coronavirususa</td>\n",
       "      <td>[humoursnlon, covid, coronavirususa]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷</td>\n",
       "      <td>#covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120</td>\n",
       "      <td>[covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1234229558699753478</td>\n",
       "      <td>Yves Gebhardt</td>\n",
       "      <td>from kofi anan, epidemics like #covid_19 are “problems without passports.” tall walls and immigration officials will not keep them out.. #funds4research\\n#letscienceeducatelawmakers\\n\\ncc @drriveramindt @6dm4\\n@cny_connections @emorycfarhttp://www.wbur.org/cognoscenti/2020/02/25/global-health-funding-coronavirus-pranay-sinha …</td>\n",
       "      <td>2020-03-01 21:30:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>from kofi anan epidemics like covid19 are problems without passports tall walls and immigration officials will not keep them out funds4researchletscienceeducatelawmakerscc drriveramindt 6dm4cnyconnections emorycfar</td>\n",
       "      <td>[kofi, anan, epidemics, like, covid19, problems, without, passports, tall, walls, immigration, officials, keep, funds4researchletscienceeducatelawmakerscc, drriveramindt, 6dm4cnyconnections, emorycfar]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1234205511349915648</td>\n",
       "      <td>Melissa Kent</td>\n",
       "      <td>un health agency @who warns against coronavirus covid-19 criminal scams https://shar.es/ahmlfb</td>\n",
       "      <td>2020-03-01 19:54:58</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>un health agency who warns against coronavirus covid19 criminal scams</td>\n",
       "      <td>[un, health, agency, warns, coronavirus, covid19, criminal, scams]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "4  1234238537068883968  enigma4ever 🌹🆘 🌊 🕊️🍑👩‍⚕️💉😷   \n",
       "5  1234229558699753478  Yves Gebhardt                \n",
       "8  1234205511349915648  Melissa Kent                 \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                       text  \\\n",
       "1  looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057 …                                                                                                                                                                                                               \n",
       "2  humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/ …                                                                                                                                                                                                                       \n",
       "4  #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/ …                                                                                                                                  \n",
       "5  from kofi anan, epidemics like #covid_19 are “problems without passports.” tall walls and immigration officials will not keep them out.. #funds4research\\n#letscienceeducatelawmakers\\n\\ncc @drriveramindt @6dm4\\n@cny_connections @emorycfarhttp://www.wbur.org/cognoscenti/2020/02/25/global-health-funding-coronavirus-pranay-sinha …   \n",
       "8  un health agency @who warns against coronavirus covid-19 criminal scams https://shar.es/ahmlfb                                                                                                                                                                                                                                             \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "5  2020-03-01 21:30:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "8  2020-03-01 19:54:58  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \\\n",
       "1  2020-02-01   \n",
       "2  2020-02-01   \n",
       "4  2020-02-01   \n",
       "5  2020-02-01   \n",
       "8  2020-02-01   \n",
       "\n",
       "                                                                                                                                                                                                               token_text  \\\n",
       "1  looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                        \n",
       "2  humoursnlon covid coronavirususa                                                                                                                                                                                         \n",
       "4  covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                     \n",
       "5  from kofi anan epidemics like covid19 are problems without passports tall walls and immigration officials will not keep them out funds4researchletscienceeducatelawmakerscc drriveramindt 6dm4cnyconnections emorycfar   \n",
       "8  un health agency who warns against coronavirus covid19 criminal scams                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                                                   stop_text  \\\n",
       "1  [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                                          \n",
       "2  [humoursnlon, covid, coronavirususa]                                                                                                                                                                        \n",
       "4  [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                                                 \n",
       "5  [kofi, anan, epidemics, like, covid19, problems, without, passports, tall, walls, immigration, officials, keep, funds4researchletscienceeducatelawmakerscc, drriveramindt, 6dm4cnyconnections, emorycfar]   \n",
       "8  [un, health, agency, warns, coronavirus, covid19, criminal, scams]                                                                                                                                          \n",
       "\n",
       "   cluster  \n",
       "1  0        \n",
       "2  0        \n",
       "4  0        \n",
       "5  0        \n",
       "8  0        "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = clean_og_df['cluster'] == 0\n",
    "clean_og_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
    "core_samples_mask[dbscan.core_sample_indices_] = True\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 5\n",
      "Estimated number of noise points: 33798\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-336a9eb35279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Estimated number of clusters: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_clusters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Estimated number of noise points: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_noise_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Homogeneity: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhomogeneity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completeness: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompleteness_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"V-measure: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_measure_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_true' is not defined"
     ]
    }
   ],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), 0)' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ac30da3f6f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_vec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_member_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcore_samples_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n\u001b[0m\u001b[1;32m     14\u001b[0m              markeredgecolor='k', markersize=14)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                 )\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key"
     ]
    }
   ],
   "source": [
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = clean_vec_df[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = clean_vec_df[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
