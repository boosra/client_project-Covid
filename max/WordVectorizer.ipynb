{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../adam/datasets/scrape_5.12.csv does not exist: '../adam/datasets/scrape_5.12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1b522d865e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../adam/datasets/scrape_5.12.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../adam/datasets/scrape_5.12.csv does not exist: '../adam/datasets/scrape_5.12.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../adam/datasets/scrape_5.12.csv')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228415289269858310</td>\n",
       "      <td>Bearjew1964</td>\n",
       "      <td>Disease modelers gaze into their computers to see the future of Covid-19, and it isn’t good https://www.statnews.com/2020/02/14/disease-modelers-see-future-of-covid-19/ … via @statnews</td>\n",
       "      <td>2020-02-14 20:26:42</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1228345808954765313</td>\n",
       "      <td>Carlos Salazar</td>\n",
       "      <td>I know we have a limited attention span and all, but this might be way more devastating than Covid-19. https://twitter.com/BBCWorld/status/1228290268857802752 …</td>\n",
       "      <td>2020-02-14 15:50:37</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1228149699145871360</td>\n",
       "      <td>Hefe O-Ren Ishii</td>\n",
       "      <td>As one Princess cruise is quarantined for COVID-19, another is hit with different illness https://www.nbcnews.com/news/us-news/one-princess-cruise-quarantined-covid-19-another-hit-different-illness-n1136436 … via @nbcnews</td>\n",
       "      <td>2020-02-14 02:51:20</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1228008158586720256</td>\n",
       "      <td>josh</td>\n",
       "      <td>how about we call it by it’s new name: COVID-19. and whats with the dramatic ass imagery? quit fear mongering, thanks</td>\n",
       "      <td>2020-02-13 17:28:54</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1227684262859636738</td>\n",
       "      <td>Helen Ong</td>\n",
       "      <td>Scorpio: To me, the #COVID_19 19, as virulent as it appears to be, is clearly containable if NYC has yet to see a confirmed case of infection. \\n\\nThe City is virtually a microcosm of the world, in numbers as well as in diversity. \\n\\n#CoronaVirus\\n#God_bless_you_Wuhan!</td>\n",
       "      <td>2020-02-12 20:01:52</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id          username  \\\n",
       "0  1228415289269858310  Bearjew1964        \n",
       "1  1228345808954765313  Carlos Salazar     \n",
       "2  1228149699145871360  Hefe O-Ren Ishii   \n",
       "3  1228008158586720256  josh               \n",
       "4  1227684262859636738  Helen Ong          \n",
       "\n",
       "                                                                                                                                                                                                                                                                             text  \\\n",
       "0  Disease modelers gaze into their computers to see the future of Covid-19, and it isn’t good https://www.statnews.com/2020/02/14/disease-modelers-see-future-of-covid-19/ … via @statnews                                                                                         \n",
       "1  I know we have a limited attention span and all, but this might be way more devastating than Covid-19. https://twitter.com/BBCWorld/status/1228290268857802752 …                                                                                                                 \n",
       "2  As one Princess cruise is quarantined for COVID-19, another is hit with different illness https://www.nbcnews.com/news/us-news/one-princess-cruise-quarantined-covid-19-another-hit-different-illness-n1136436 … via @nbcnews                                                    \n",
       "3  how about we call it by it’s new name: COVID-19. and whats with the dramatic ass imagery? quit fear mongering, thanks                                                                                                                                                            \n",
       "4  Scorpio: To me, the #COVID_19 19, as virulent as it appears to be, is clearly containable if NYC has yet to see a confirmed case of infection. \\n\\nThe City is virtually a microcosm of the world, in numbers as well as in diversity. \\n\\n#CoronaVirus\\n#God_bless_you_Wuhan!   \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-02-14 20:26:42  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-02-14 15:50:37  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-02-14 02:51:20  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-02-13 17:28:54  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-02-12 20:01:52  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \n",
       "0  2020-02-01  \n",
       "1  2020-02-01  \n",
       "2  2020-02-01  \n",
       "3  2020-02-01  \n",
       "4  2020-02-01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96507, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str).str.lower()\n",
    "df['token_text'] = df['text'].str.replace('([^ a-zA-Z0-9])', '').str.replace('http\\S+|www.\\S+', '', case=False).replace('coronavirus', 'covid19')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['stop_text'] = df['token_text'].apply(lambda x: [item for item in str(x).split() \n",
    "                                                    if item not in stop])\n",
    "\n",
    "\n",
    "\n",
    "#df['split_text'] = df['token_text'].astype(str).str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    disease modelers gaze into their computers to see the future of covid-19, and it isn’t good https://www.statnews.com/2020/02/14/disease-modelers-see-future-of-covid-19/ … via @statnews                                                                                      \n",
       "1    i know we have a limited attention span and all, but this might be way more devastating than covid-19. https://twitter.com/bbcworld/status/1228290268857802752 …                                                                                                              \n",
       "2    as one princess cruise is quarantined for covid-19, another is hit with different illness https://www.nbcnews.com/news/us-news/one-princess-cruise-quarantined-covid-19-another-hit-different-illness-n1136436 … via @nbcnews                                                 \n",
       "3    how about we call it by it’s new name: covid-19. and whats with the dramatic ass imagery? quit fear mongering, thanks                                                                                                                                                         \n",
       "4    scorpio: to me, the #covid_19 19, as virulent as it appears to be, is clearly containable if nyc has yet to see a confirmed case of infection. \\n\\nthe city is virtually a microcosm of the world, in numbers as well as in diversity. \\n\\n#coronavirus\\n#god_bless_you_wuhan!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [disease, modelers, gaze, computers, see, future, covid19, isnt, good, via, statnews]                                                                                                               \n",
       "1    [know, limited, attention, span, might, way, devastating, covid19]                                                                                                                                  \n",
       "2    [one, princess, cruise, quarantined, covid19, another, hit, different, illness, via, nbcnews]                                                                                                       \n",
       "3    [call, new, name, covid19, whats, dramatic, ass, imagery, quit, fear, mongering, thanks]                                                                                                            \n",
       "4    [scorpio, covid19, 19, virulent, appears, clearly, containable, nyc, yet, see, confirmed, case, infection, city, virtually, microcosm, world, numbers, well, diversity, coronavirusgodblessyouwuhan]\n",
       "Name: stop_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    disease modelers gaze into their computers to see the future of covid19 and it isnt good  via statnews                                                                                                                                               \n",
       "1    i know we have a limited attention span and all but this might be way more devastating than covid19                                                                                                                                                  \n",
       "2    as one princess cruise is quarantined for covid19 another is hit with different illness  via nbcnews                                                                                                                                                 \n",
       "3    how about we call it by its new name covid19 and whats with the dramatic ass imagery quit fear mongering thanks                                                                                                                                      \n",
       "4    scorpio to me the covid19 19 as virulent as it appears to be is clearly containable if nyc has yet to see a confirmed case of infection the city is virtually a microcosm of the world in numbers as well as in diversity coronavirusgodblessyouwuhan\n",
       "Name: token_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row for row in df['stop_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v = Word2Vec(size=1000, min_count=100, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v.build_vocab(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('likely', 0.10515736043453217),\n",
       " ('fashion', 0.09170820564031601),\n",
       " ('statenisland', 0.08865690976381302),\n",
       " ('individuals', 0.0873868465423584),\n",
       " ('drug', 0.08693991601467133),\n",
       " ('followers', 0.08176644891500473),\n",
       " ('calling', 0.08068063110113144),\n",
       " ('photo', 0.07962851226329803),\n",
       " ('cuomo', 0.07908006757497787),\n",
       " ('hour', 0.07829046249389648)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
