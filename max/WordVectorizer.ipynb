{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../adam/datasets/scrape_5.12.csv')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>Did the first of several shopping runs, though I ended up walking out of CVS without buying anything. If the rate of people coughing at me is any indication, we‚Äôll all have Covid-19 by Thursday. \\n\\nCover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>Looks like adios muchachos for the US #COVID #COVID19US #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>Humour..snl...on #COVID #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>¬∞ ¬∞ ¬∞</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>#COVID #Coronovirius in nursing home setting , #Kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "3  1234238588474331136  ¬∞ ¬∞ ¬∞                        \n",
       "4  1234238537068883968  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  Did the first of several shopping runs, though I ended up walking out of CVS without buying anything. If the rate of people coughing at me is any indication, we‚Äôll all have Covid-19 by Thursday. \\n\\nCover your fucking mouths when you cough.   \n",
       "1  Looks like adios muchachos for the US #COVID #COVID19US #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                       \n",
       "2  Humour..snl...on #COVID #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #COVID #Coronovirius in nursing home setting , #Kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \n",
       "0  2020-02-01  \n",
       "1  2020-02-01  \n",
       "2  2020-02-01  \n",
       "3  2020-02-01  \n",
       "4  2020-02-01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114044, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str).str.lower()\n",
    "df['token_text'] = df['text'].str.replace('([^ a-zA-Z0-9])', '').str.replace('http\\S+|www.\\S+', '', case=False).replace('coronavirus', 'covid19')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['stop_text'] = df['token_text'].apply(lambda x: [item for item in str(x).split() \n",
    "                                                    if item not in stop])\n",
    "\n",
    "\n",
    "\n",
    "#df['split_text'] = df['token_text'].astype(str).str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.\n",
       "1    looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                    \n",
       "2    humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                            \n",
       "3    had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                    \n",
       "4    #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                       \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]\n",
       "1    [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                  \n",
       "2    [humoursnlon, covid, coronavirususa]                                                                                                                                                \n",
       "3    [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]              \n",
       "4    [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                         \n",
       "Name: stop_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough\n",
       "1    looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                    \n",
       "2    humoursnlon covid coronavirususa                                                                                                                                                                                                     \n",
       "3    had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan               \n",
       "4    covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                 \n",
       "Name: token_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row for row in df['stop_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v = Word2Vec(size=dims, min_count=500, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v.build_vocab(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('story', 0.10644198954105377),\n",
       " ('due', 0.08200381696224213),\n",
       " ('closed', 0.08182897418737411),\n",
       " ('use', 0.08138839900493622),\n",
       " ('make', 0.0757923275232315),\n",
       " ('listen', 0.07085724920034409),\n",
       " ('damn', 0.07065573334693909),\n",
       " ('may', 0.06945273280143738),\n",
       " ('month', 0.06770958006381989),\n",
       " ('please', 0.0654895231127739)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions found in this cell were created by instructor Noah Christiansen\n",
    "# He is great\n",
    "# Define vectorization function\n",
    "#word2vecmodel = tweet_w2v\n",
    "def vectorize_corpus(keyword_list):    \n",
    "    # Instantiate counter for number of words in keyword_list that exists\n",
    "    n_words = 0\n",
    "    # Create template for cumulative corpus vector sum\n",
    "    corpus_vec_sum = np.zeros((1,dims))                 \n",
    "    # Scan through each word in list\n",
    "    for word in keyword_list:\n",
    "        if word in tweet_w2v.wv.vocab:                    \n",
    "            word_vec = tweet_w2v.wv.word_vec(word)\n",
    "            #print(word_vec)\n",
    "            n_words +=1                                \n",
    "            corpus_vec_sum = corpus_vec_sum + word_vec \n",
    "    # Compute average vector by taking cumulative vector sum and dividing it by number of words traced\n",
    "    corpus_avg_vec = corpus_vec_sum/n_words\n",
    "    # Squeeze this N-dimensional nested array object into a 1-D array to streamline future processing\n",
    "    corpus_avg_vec = np.squeeze(corpus_avg_vec)\n",
    "    return(corpus_avg_vec)\n",
    "\n",
    "#defining cosine similarity function\n",
    "def cos_sim(vector_1, vector_2):\n",
    "    dp = np.dot(vector_1, vector_2)\n",
    "    magnitude_v1 = np.sqrt(np.dot(vector_1,vector_1))\n",
    "    magnitude_v2 = np.sqrt(np.dot(vector_2,vector_2))\n",
    "    return(dp/(magnitude_v1*magnitude_v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "vect_tweets = [vectorize_corpus(tweet) for tweet in df['stop_text']]\n",
    "vect_df = pd.DataFrame(vect_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = df.join(vect_df)\n",
    "join_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.707658e-04</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-1.625748e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>-1.359438e-07</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>4.043558e-05</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-9.801134e-05</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0 -0.000112 -0.000049  0.000016  0.000080 -0.000060  0.000096 -0.000071   \n",
       "1 -0.000173 -0.000046  0.000031  0.000058 -0.000042  0.000137 -0.000024   \n",
       "2 -0.000273 -0.000028 -0.000086 -0.000250  0.000319  0.000260  0.000279   \n",
       "3  0.000048 -0.000149  0.000033 -0.000090 -0.000021  0.000024 -0.000065   \n",
       "4 -0.000067  0.000118 -0.000040 -0.000163 -0.000016  0.000094  0.000045   \n",
       "\n",
       "          8         9        10  ...       990       991       992       993  \\\n",
       "0 -0.000039 -0.000068  0.000029  ...  0.000032  0.000024 -0.000140  0.000148   \n",
       "1  0.000016  0.000144 -0.000099  ...  0.000111  0.000051  0.000125 -0.000147   \n",
       "2  0.000329  0.000115 -0.000319  ...  0.000463  0.000271  0.000484 -0.000458   \n",
       "3  0.000075  0.000013  0.000010  ...  0.000143  0.000047  0.000072  0.000043   \n",
       "4  0.000174  0.000100 -0.000195  ... -0.000142  0.000070  0.000006  0.000171   \n",
       "\n",
       "        994       995       996           997       998       999  \n",
       "0 -0.000055  0.000018  0.000080  1.707658e-04 -0.000015 -0.000019  \n",
       "1 -0.000011  0.000095  0.000015 -1.625748e-04  0.000014  0.000062  \n",
       "2 -0.000035 -0.000259 -0.000462 -1.359438e-07  0.000488  0.000259  \n",
       "3  0.000107 -0.000048 -0.000033  4.043558e-05  0.000223 -0.000078  \n",
       "4  0.000142  0.000051  0.000048 -9.801134e-05  0.000114  0.000032  \n",
       "\n",
       "[5 rows x 999 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_vec_df= join_df.iloc[:, [i for i in range(13,dims+12)]]\n",
    "clean_og_df = join_df.iloc[:, [i for i in range(0,12)]]\n",
    "clean_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "      <th>token_text</th>\n",
       "      <th>stop_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234258409408602118</td>\n",
       "      <td>e.p.c.</td>\n",
       "      <td>did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.</td>\n",
       "      <td>2020-03-01 23:25:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough</td>\n",
       "      <td>[first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234253374725459968</td>\n",
       "      <td>@geminiwoe</td>\n",
       "      <td>looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 23:05:10</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>looks like adios muchachos for the us covid covid19us coronavirus</td>\n",
       "      <td>[looks, like, adios, muchachos, us, covid, covid19us, coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234241890700218370</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:19:32</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>humoursnlon covid coronavirususa</td>\n",
       "      <td>[humoursnlon, covid, coronavirususa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234238588474331136</td>\n",
       "      <td>¬∞ ¬∞ ¬∞</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.</td>\n",
       "      <td>2020-03-01 22:06:25</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan</td>\n",
       "      <td>[go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234238537068883968</td>\n",
       "      <td>enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑</td>\n",
       "      <td>#covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶</td>\n",
       "      <td>2020-03-01 22:06:12</td>\n",
       "      <td>COVID</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>40.650002</td>\n",
       "      <td>-73.949997</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120</td>\n",
       "      <td>[covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                    username  \\\n",
       "0  1234258409408602118  e.p.c.                       \n",
       "1  1234253374725459968  @geminiwoe                   \n",
       "2  1234241890700218370  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "3  1234238588474331136  ¬∞ ¬∞ ¬∞                        \n",
       "4  1234238537068883968  enigma4ever üåπüÜò üåä üïäÔ∏èüçëüë©‚Äç‚öïÔ∏èüíâüò∑   \n",
       "\n",
       "                                                                                                                                                                                                                                               text  \\\n",
       "0  did the first of several shopping runs, though i ended up walking out of cvs without buying anything. if the rate of people coughing at me is any indication, we‚Äôll all have covid-19 by thursday. \\n\\ncover your fucking mouths when you cough.   \n",
       "1  looks like adios muchachos for the us #covid #covid19us #coronavirushttps://twitter.com/nytimes/status/1234171621696557057¬†‚Ä¶                                                                                                                       \n",
       "2  humour..snl...on #covid #coronavirususahttps://mashable.com/video/snl-coronavirus-democratic-candidates-cold-open/¬†‚Ä¶                                                                                                                               \n",
       "3  had to go to three diff convenient stores to find real milk (not soy) and they were all out of the lower priced non organic stuff .. i buy organic so i was fine with it but wow. covid 19 panic buying begins in manhattan.                       \n",
       "4  #covid #coronovirius in nursing home setting , #kirkland more than 50 with symptoms ..3/1/20https://www.statnews.com/2020/02/29/new-covid-19-death-raises-concerns-about-virus-spread-in-nursing-homes/¬†‚Ä¶                                          \n",
       "\n",
       "            tweet_date search_term      city        lat       long radius  \\\n",
       "0  2020-03-01 23:25:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "1  2020-03-01 23:05:10  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "2  2020-03-01 22:19:32  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "3  2020-03-01 22:06:25  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "4  2020-03-01 22:06:12  COVID       Brooklyn  40.650002 -73.949997  10mi    \n",
       "\n",
       "  query_start  \\\n",
       "0  2020-02-01   \n",
       "1  2020-02-01   \n",
       "2  2020-02-01   \n",
       "3  2020-02-01   \n",
       "4  2020-02-01   \n",
       "\n",
       "                                                                                                                                                                                                                              token_text  \\\n",
       "0  did the first of several shopping runs though i ended up walking out of cvs without buying anything if the rate of people coughing at me is any indication well all have covid19 by thursday cover your fucking mouths when you cough   \n",
       "1  looks like adios muchachos for the us covid covid19us coronavirus                                                                                                                                                                       \n",
       "2  humoursnlon covid coronavirususa                                                                                                                                                                                                        \n",
       "3  had to go to three diff convenient stores to find real milk not soy and they were all out of the lower priced non organic stuff  i buy organic so i was fine with it but wow covid 19 panic buying begins in manhattan                  \n",
       "4  covid coronovirius in nursing home setting  kirkland more than 50 with symptoms 3120                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                              stop_text  \n",
       "0  [first, several, shopping, runs, though, ended, walking, cvs, without, buying, anything, rate, people, coughing, indication, well, covid19, thursday, cover, fucking, mouths, cough]  \n",
       "1  [looks, like, adios, muchachos, us, covid, covid19us, coronavirus]                                                                                                                    \n",
       "2  [humoursnlon, covid, coronavirususa]                                                                                                                                                  \n",
       "3  [go, three, diff, convenient, stores, find, real, milk, soy, lower, priced, non, organic, stuff, buy, organic, fine, wow, covid, 19, panic, buying, begins, manhattan]                \n",
       "4  [covid, coronovirius, nursing, home, setting, kirkland, 50, symptoms, 3120]                                                                                                           "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_og_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-78ad0b5d43d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdbscan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# you can change these parameters, given just for example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_vec_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# where X - is your matrix, where each row corresponds to one document (line) from the docs, you need to cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNoisy\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mare\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         neighborhoods = neighbors_model.radius_neighbors(X,\n\u001b[0;32m--> 335\u001b[0;31m                                                          return_distance=False)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mneigh_ind_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_ind_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1592\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1593\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1594\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     Parallel(backend=\"threading\", n_jobs=n_jobs)(\n\u001b[1;32m   1354\u001b[0m         \u001b[0mfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         for s in gen_even_slices(_num_samples(Y), effective_n_jobs(n_jobs)))\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dsi/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(metric='cosine', eps=0.4, min_samples=30, n_jobs = -1) # you can change these parameters, given just for example \n",
    "cluster_labels = dbscan.fit_predict(clean_vec_df) # where X - is your matrix, where each row corresponds to one document (line) from the docs, you need to cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_og_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_og_df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = clean_og_df['cluster'] == 22\n",
    "clean_og_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
